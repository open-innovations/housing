{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] The geography tree is as follows: LADs/Met counties/counties/combined authorities => Regions => England/Wales/Scotland/NI. \n",
    "- [x] Lookups for the most recent names and codes of these geographies have been downloaded into `data/lookups`.\n",
    "- [x] To generate a list of active geographies we combined all of these lookups into a single file with the column titles `geography_code` and `geography_name`. This is temporarily stored in `metadata/temp`.\n",
    "- [x] Each data set may contain some/all or none of these geographies. Per dataset, we iterate through each file's unique geographies and check if they are in the list of active codes. If they are not, we add them to a list of inactive codes stored in `metadata/temp`.\n",
    "- [] For all geographies we determine when data was first and last published per dataset.\n",
    "- [] This is stored in a `JSON` file in `src/data/areas/place-page/_data/metadata.json` and used to generate the site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and set up paths for reading and writing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/lukestrange/Code/housing')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "ROOT = Path('../..')\n",
    "ROOT.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_geographies = pd.DataFrame()\n",
    "paths = [\n",
    "    \"metadata/lookups/Local_Authority_Districts_(April_2023)_Names_and_Codes_in_the_United_Kingdom.csv\", \n",
    "    \"metadata/lookups/Metropolitan_Counties_(December_2023)_Names_and_Codes_in_EN.csv\", \n",
    "    \"metadata/lookups/Regions_(December_2023)_Names_and_Codes_in_EN.csv\",\n",
    "    \"metadata/lookups/Combined_Authorities_(May_2024)_Names_and_Codes_in_England.csv\",\n",
    "    \"metadata/lookups/Counties_(April_2023)_Names_and_Codes_in_EN.csv\",\n",
    "    \"metadata/lookups/Countries_(December_2023)_Names_and_Codes_in_the_UK.csv\"\n",
    "    ]\n",
    "for path in paths:\n",
    "    data = pd.read_csv(ROOT / path)\n",
    "    code_name = data.columns[data.columns.str.endswith('CD')].values[0]\n",
    "    geo_name = data.columns[data.columns.str.endswith('NM')].values[0]\n",
    "    data.rename(columns={f'{code_name}': 'geography_code', f'{geo_name}': 'geography_name'}, inplace=True)\n",
    "    data = data[['geography_code', 'geography_name']]\n",
    "    active_geographies = pd.concat([active_geographies, data])\n",
    "\n",
    "active_geographies = active_geographies[~active_geographies['geography_code'].str.startswith(('W', 'S', 'N', 'K'))]\n",
    "active_geographies.reset_index(inplace=True, drop=True)\n",
    "active_geographies['active'] = 'true'\n",
    "active_geographies.set_index('geography_code', inplace=True)\n",
    "active_geographies.to_json(ROOT / 'metadata/temp/active_geographies.json', orient='index', indent=4)\n",
    "\n",
    "len(active_geographies.geography_name.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inactive geographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [ROOT / 'data/vacant-homes/AllCombined_Cleaned_2024.csv', ROOT / 'data/house-prices/median_house_prices.csv', ROOT / 'data/affordable-homes/by_tenure.csv']\n",
    "inactive_geographies = pd.DataFrame(columns=['geography_code', 'geography_name'])\n",
    "for file in files:\n",
    "    # Read the file\n",
    "    d = pd.read_csv(file)\n",
    "    \n",
    "    columns = d.columns.to_list()\n",
    "    assert 'geography_code' in columns, 'No column geography_code'\n",
    "    assert 'geography_name' in columns, 'No column geography_name'\n",
    "\n",
    "    # Group the names and codes to get unique combinations, drop the size column.\n",
    "    d = d.groupby(['geography_code', 'geography_name']).size().reset_index().drop(columns=0)\n",
    "\n",
    "    # fix some known naming bugs.\n",
    "    d['geography_name'] = d['geography_name'].str.replace('&', 'and')\n",
    "    d['geography_name'] = d['geography_name'].str.replace('St Edmundsbury', 'St. Edmundsbury')\n",
    "\n",
    "    # Ensure no duplicates remain\n",
    "    d.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Get lists of unique codes and names in the current dataset\n",
    "    unique_active_codes = active_geographies.index.unique()\n",
    "    unique_active_names = active_geographies['geography_name'].unique()\n",
    "    df_A = active_geographies.reset_index().drop(columns='active')\n",
    "    df_B = d\n",
    "    # Merge DataFrames with indicator to show the source of each row\n",
    "    merged_df = df_B.merge(df_A, how='left', indicator=True)\n",
    "\n",
    "    # Filter rows that are only in DataFrame B\n",
    "    unique_to_B = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "    # Drop the _merge column\n",
    "    unique_to_B = unique_to_B.drop(columns='_merge')\n",
    "    inactive_geographies = pd.concat([unique_to_B, inactive_geographies])\n",
    "\n",
    "# Set the active status remaining geographies to false\n",
    "inactive_geographies['active'] = 'false'\n",
    "\n",
    "inactive_geographies.set_index('geography_code', inplace=True)\n",
    "# Drop any duplicates that came from multiple files\n",
    "inactive_geographies.drop_duplicates(inplace=True)\n",
    "inactive_geographies.to_json(ROOT / 'metadata/temp/inactive_geographies.json', orient='index', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains no duplicates...\n",
      " writing to JSON file.\n"
     ]
    }
   ],
   "source": [
    "combined = pd.concat([active_geographies, inactive_geographies])\n",
    "dupes = combined[combined.index.duplicated()]\n",
    "if dupes.empty:\n",
    "    print('Contains no duplicates...\\n writing to JSON file.')\n",
    "    combined.to_json(ROOT / \"metadata/UK_geo_activity_status.json\", orient='index', indent=4)\n",
    "else: \n",
    "    print(dupes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing-2Roxq_cV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
